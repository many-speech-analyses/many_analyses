Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15,q6
neosilurus_omanensis,90,90,90,publishable as is.,"Audio and text-grids were automatically force-aligned using software for this purpose, and a part of this alignment was double-checked by human annotators. Automated force-alignment needed to be used anyway due to time and financial constraints. Human-annotated data was used when available, and the remaining data used came from the automatic force-alignment. Four pitch-related variables were used (pitch ratio of the adjective, pitch range ratio of the adjective, pitch variation ratio within the adjective, pitch change ratio within the adjective) as well as speech ratio. Using five acoustic cues certainly enriches the analysis, though we understood that only one dependent variable should have been used.","Linear regression models were appropriately used for the analysis. For each dependent variable (there were 5, see comment on previous and next questions) two models were fitted, one with 'typicality' as an independent variable, and another adding 'context' and an interaction between typicality and context. Models were compared and the more complex model was used only if it added significant information. Analysts included varying terms for participant and adjective when the model converged, and dropped them when convergion was an issue, but did not mention if only varying intercepts or also varying slopes were included. When varying terms were dropped, they did mention which one(s) ended up being dropped.
Statistical analysis was appropriate. Analysts made sensible adjustments to p-value interpretation (raising alpha for the one-tailed interpretation, but also correcting p-values for multiple comparisons). They also calculated effect sizes, which were in general very small (though analysts did not comment much about them). All information provided by the models (beta coefficients, p-values and effect sizes) led to the conclusion of no effect of typicality.","A total of ten models were fitted, and five were reported, since five dependent variables were used for the analysis (4 related to pitch and 1 to speech rate). Correction for multiple comparisons was done. This is very informative for the analysis, though we understood that  each team should have selected only one dependent variable and therefore only one statistical model to be reported. The dependent variables were:
1) Pitch ratio of the adjective
2) Pitch range ratio of the adjective 
3) Pitch variation ratio within the adjective
4) Pitch change ratio within the adjective
5) Speech rate (articulation rate) of the adjective","Procedures for including/excluding variables, which have already been commented on, were appropriate.","The structure of the statistical models was suitable, as already commented on.","Speech rate outliers of more than two standard deviations from the participantâ€™s mean were deleted. Also, for both adjective and sentence, the pitch minimum and maximum and the pitch range of the first 10% and last 10% were deleted if they exceeded the range of the mean plus/minus two standard deviations. The amount of deleted values was considerable, especially for maxima and minima, which affected the analysis of pitch range and pitch rise, but since the remaining data were still balanced, they were used.",There was no data transformation.,NA,3
neosilurus_omanensis,95,95,95,publishable with minor revision.,The team needs to elaborate clearly on the outliers issue. The criteria of deleting the outliers was not clear enough for readers. Is every false response or error an outlier?,The two models are good. But the authors have to clarify the reason behind the effect size's formula used in their analysis.,Very good.,The authors need to clarify the differences between errors found in the original data and the outliers.,Very good.,Good,Good,NA,2
neosilurus_omanensis,64,60,62,publishable with major revision.,"Overall, we felt that this analysis was well done, but with some changes that should be made that would strengthen our confidence in the results.","Mixed models were appropriate,",It seems like this was motivated by theory in an acceptable way.,The variables were appropriate for the research questions.,"It would have been nice to see random slopes used, as this was in theory a confirmatory hypothesis test.","An unknown amount of observations were removed for lying outside two standard deviations from the mean. This is not an appropriate statistical practice. If you wanted to check the influence of outliers, we would advise doing so within the regression model as part of model criticism as suggested by Baayen and Milin (2010).

Many times it seemed like large amounts of data were missing. It is important to acknowledge that missing data is a problem if the data is missing for a reason related to how the data was generated.

",NA,NA,1
neosilurus_omanensis,70,30,50,publishable with major revision.,"The phonetic analysis has touched on some good points, and the consideration on segmentation and measurements selection were reasonable. However, it is not clear if it is appropriate to measure the F0 of the entire sentence inclusive of all the unvoiced segments/segments that fail the pitch tracker. The F0 measurement algorithm and measures' calculation processes were not explained.
The statistical analysis was conducted with the model misspecified. The significance reporting was also problematic that the authors were using 0.1 as the threshold. A few errors of significance were seen. FDR should be used earlier in the results section rather than a separate section to correct the significance of results.",The choice of mixed effect model was fine for this problem.,"The two model setups appear circular and debatable. The authors designed the two models to test two separate hypotheses in the first place. However, in the following Analysis and Results sections, they changed the effective model depending on whether Model 2 explains more variance than Model 1. It seems that the authors conflated hypothesis testing and model selection. If the authors believe that different focus conditions play a role in predicting the DVs, then ""context"" should always be included in the models, not selecting a different model for each DV based on whether more variance was explained by ""context"", which is circular. 

Moreover, to address the first hypothesis, it does not make sense to include the adjs in all the conditions, because in the NF condition adjectives are not part of the experimental manipulation of typicality, making the stats problematic. In general, context conditions should be analyzed separately under each condition due to experiment design, but the authors mingled it together as an independent variable.","Not subsetting adjs in only AF & ANF conditions is not appropriate. In addition, it would be better to discuss the potential of variable interaction for the 5 selected response variables.",The structure of the model needs major revision.,"The authors excluded too much observations based on predetermined rules. However, as the authors mentioned, this resulted in too few data points to work with with potentially many outliers, thus not a good practice.","It is questionable to use mean, instead of median, to normalize F0, as F0 distribution is likely not normal. The speech rate measurements should be normalized, as the unit used by the authors might introduce large coefficients which may make the probability estimation unstable.",NA,1
