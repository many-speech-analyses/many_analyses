---
title: "OSF management"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
knitr::opts_knit$set(root.dir = here::here())
library(here)
library(tidyverse)
library(osfr)
library(speakr)
library(glue)
library(googlesheets4)
```

# Manage OSF with osfr

This document contains the code used to manage the OSF repo with the [osfr](https://docs.ropensci.org/osfr/) package.

# Retrieve OSF Data component

```{r retrieve}
# Main repo "Many Speech Analysis": https://osf.io/3bmcp/
osf_data <- osf_retrieve_node("5agn9")
```

# Prepare files

## Readme files

We can knit the readme files (they are GitHub documents, i.e. `.Rmd` files that are converted to `.md` files upon knitting).

```{r knit-readmes, message=FALSE, warning=FALSE}
readme_rmds <- list.files("./data/osf", pattern = "[.]Rmd$", recursive = T, full.names = T)

for (f in readme_rmds) {
  xfun::Rscript_call(rmarkdown::render, list(f))
}
```

## Norming study

```{r ratings}
ratings <- read_csv("./data/dataset/ratings.csv") %>%
  mutate(
    # Fix wrong encoding
    object = str_replace(object, "W�_scheklammer", "Waescheklammer"),
    object = str_replace(object, "M̦hre", "Moehre"),
  ) %>%
  rename(prolific_id = `prolific id`) %>%
  select(prolific_id, object, colour, typicality) %>%
  arrange(prolific_id, object, colour) %>%
  mutate(
    object_en = case_when(
      object == "Ananas" ~ "pineapple",
      object == "Aprikose" ~ "apricot",
      object == "Aubergine" ~ "aubergine",
      object == "Avocado" ~ "avocado",
      object == "Banane" ~ "banana",
      object == "Birne" ~ "pear",
      object == "Bohnen" ~ "beans",
      object == "Bueroklammer" ~ "paper.clip",
      object == "Erbsen" ~ "peas",
      object == "Erdbeere" ~ "strawberry",
      object == "Gurke" ~ "cucumber",
      object == "Kartoffeln" ~ "potatoes",
      object == "Kirsche" ~ "cherry",
      object == "Mandarine" ~ "mandarine",
      object == "Moehre" ~ "carrots",
      object == "Paprika" ~ "pepper",
      object == "Socken" ~ "socks",
      object == "Sonnenbrille" ~ "suglasses",
      object == "Tomate" ~ "tomato",
      object == "Trauben" ~ "grapes",
      object == "Waescheklammer" ~ "clothes.peg",
      object == "Walnuss" ~ "walnut",
      object == "Zitrone" ~ "lemon",
      object == "Zucchini" ~ "courgettes"
    ),
    colour_en = case_when(
      colour == "blau" ~ "blue",
      colour == "braun" ~ "brown",
      colour == "gelb" ~ "yellow",
      colour == "grau" ~ "gray",
      colour == "gruen" ~ "green",
      colour == "lila" ~ "lilac",
      colour == "orange" ~ "orange",
      colour == "rot" ~ "red",
      colour == "schwarz" ~ "black"
    )
  )

write_csv(ratings, "./data/osf/norming/ratings/ratings.csv")

ratings_summary <- ratings %>%
  group_by(object, colour, object_en, colour_en) %>%
  summarise(
    typ_mean = mean(typicality),
    typ_sd = sd(typicality),
    typ_median = median(typicality),
    .groups = "drop"
  )

write_csv(ratings_summary, "./data/osf/norming/ratings/ratings_summary.csv")
```

## Production study

```{r textgrids}
praat_run("./scripts/praat/prep_textgrids.praat")
```

```{r tlists}
tlists <- list.files("./data/trial-lists", ".csv", full.names = TRUE)
typ <- read_csv("./data/dataset/typicality.csv")

for (tlist in tlists) {
  speaker <- str_sub(tlist, 20, 23) %>%
    str_remove("\\.c")
  tbl <- read_csv(tlist) %>%
    mutate(
      speaker = speaker,
      trial = row_number()
    ) %>%
    left_join(y = typ) %>%
    select(speaker, trial, condition, typicality, everything()) %>%
    mutate(typicality = ifelse(condition == "NF", typicality, NA)) %>%
    left_join(y = ratings_summary, by = c("target_name" = "object", "target_colour" = "colour"))
  
  write_csv(tbl, file = paste0("./data/osf/production/trial-lists/", speaker, ".csv"))
}
```

# Upload files

```{r upload-files, eval=FALSE}
osf_upload(osf_data, path = "./data/osf/norming", recurse = T, verbose = T)
osf_upload(osf_data, path = "./data/osf/production", recurse = T, verbose = T)
osf_upload(osf_data, path = "./data/osf/README.md", recurse = T, verbose = T)
osf_upload(osf_data, path = "./data/osf/methods_norm_prod.pdf", recurse = T, verbose = T)
```

# Create teams components

```{r teams-create, eval=FALSE}
osf_teams <- osf_retrieve_node("n3fyd")
teams <- list("echeneis_occidentale", "butis_texana", "choerodon_retusa", "paralichthys_undulatus", "stygobromus_tyraica", "pseudechidna_nubiae", "hoplostethus_macrosteus", "gorgasia_eleutherus", "trachurus_riukiuensis", "berardius_roseicapilla", "petauroides_fistulator", "polymetme_brevirostrum", "epinephelus_aztecus", "eriphia_laterispinis", "varanus_eulophotes", "genyonemus_evotis", "saron_pictus", "kryptopterus_megistos", "dermatolepis_aculeatus", "ornithorhynchus_ruficapillus", "manupecten_pearcei", "swiftia_ruber", "neosilurus_omanensis", "hoplostethus_binoculata", "pseudodax_euryzona", "haematopus_fossor", "anthracoceros_coronata", "lasionycteris_altavela", "lycodes_bradfieldi", "gymnothorax_spinulosus", "trigonias_lachneri", "anomalocaris_ornata", "trapezia_cantonensis", "comanthina_maculatus", "plectorhinchus_virens", "arapaima_modularis", "naso_cassivellaunos", "opsanus_caryi", "linckia_nattereri", "pseudobalistes_placidus", "pervagor_adscensionis", "gnathosaurus_canadensis", "ctenosaura_limax", "cromileptes_saxatilis", "eosipterus_pytyopsittacus", "psittacula_scabriculus", "clione_dorsalis", "nestor_idahoensis", "sphyrna_ellioti", "chelonia_brummeri", "pseudopleuronectes_assasi", "aratinga_lugubris", "muriceopsis_polydactyla", "procambarus_maculosus", "procambarus_mahogoni", "ceratophrys_elephantotus", "callorhinchus_libratus", "seigisaurus_cristatus", "pervagor_meeki", "lepophidium_ochropus", "trachyphyllia_lappa", "aracana_bitatawa", "dunkleosteus_inscriptus", "auchenoglanis_capriscus", "aphaniotis_alcockii", "prionotus_herodias", "acanthopagrus_signatus", "orohippus_quadricornis", "alosa_atun", "priodontes_geoffroanus", "stenomylus_hemistiktos", "parabuthus_pusilla", "anolis_nebularia", "taenianotus_cassivellaunos", "camptosaurus_antennatus", "koskinonodon_porrasi", "acanthodoras_hoehnelii", "hoplolatilus_canus", "rhinopias_brevicarpalis", "echinus_pavoninus", "cataetyx_regius", "dorudon_fossor", "notopterus_ventricosus", "corystes_communis", "cardisoma_arabicum", "favia_longus", "sternoptyx_derasa", "peltocephalus_meleagris", "dicynodon_rubra", "stauroteuthis_newberryi", "chauliodus_melanopus", "sternarchorhynchus_thamnobates", "thrinaxodon_scomberoides", "dermochelys_glaucum", "monocirrhus_qilixaensis", "symphurus_altavela", "gorgasia_jamaicensis", "porcellana_ringens", "montipora_gigantea", "arctonyx_glaucum")

walk(
  teams,
  function(team) {
    osf_create_component(osf_teams, team, category = "analysis")
  }
)
```

# Download team components

```{r teams-comps, eval=FALSE}
osf_teams <- osf_retrieve_node("n3fyd")
# Warning, takes a minute
teams_comps <- osf_ls_nodes(osf_teams, n_max = Inf)
assigned <- read_sheet("https://docs.google.com/spreadsheets/d/1OOXB-8Uk-fh_urw0Lm4DC0jBueXLIb4Bm-a9--UVXOw/edit?usp=sharing")
```

```{r teams-download, eval=FALSE}
my_assignment <- assigned %>%
  # ste, joseph, or timo
  filter(assigned_to == "ste") %>%
  pull(animal)

for (team in 1:length(my_assignment)) {
  skip_to_next <- FALSE
  
  name <- my_assignment[team]
  dir.create(glue("./data/teams_analyses/{name}"), recursive = TRUE, showWarnings = FALSE)
  
  tryCatch(
    osf_ls_files(teams_comps[team,], type = "folder") %>%
      osf_download(
        path = glue("./data/teams_analyses/{name}"),
        recurse = TRUE, verbose = TRUE, progress = TRUE, conflicts = "skip"
      ),
    error = function(e) { skip_to_next <<- TRUE}
  )
  
  if(skip_to_next) { next }
}
```

# Upload analytic questionnaire answers.

Ugly code to do the job quickly. Need a-fixing.

```{r upload-analytic-responses}
teams_analyses <- read_csv("data/questionnaires/msa_data_analysis_questionnaire_cleaned.csv")

teams <- teams_analyses$Q17
teams_files <- paste0(teams, ".txt")

for (team in 1:length(teams)) {
  file_path <- glue("data/questionnaires/msa_data_analysis_files/{teams[team]}.txt")
  osf_upload(teams_comps[which(teams_comps$name == teams[team]),], path = file_path, verbose = T, conflicts = "overwrite")
}
```

```{r delete-analytic-responses}
for (team in teams) {
  file_name <- glue("{team}.txt")
  file_id <- osf_ls_files(teams_comps[which(teams_comps$name == team),], pattern = ".txt")
  if (nrow(file_id) > 0) {
    for (file in 1:nrow(file_id)) {
      if (file_id$name[file] %in% teams_files) {
        osf_rm(file_id[file,], check = FALSE)
      }
    }
  }
}
```

# Delete empty components

```{r delete-comps}
for (team_idx in 1:nrow(teams_comps)) {
  if (!(teams_comps[team_idx,]$name %in% teams)) {
    osf_rm(teams_comps[team_idx,], check = FALSE, verbose = TRUE, recurse = TRUE)
  }
}
```

