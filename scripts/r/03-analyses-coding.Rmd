---
title: "03 - Analyses coding"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
library(tidyverse)
library(ggmosaic)
library(googlesheets4)
library(magrittr)
library(glue)
library(osfr)
library(cli)
library("here")
library("fs")
library("forcats")
library("strex")
library("purrr")
library("broom")
library("broom.mixed")
```

# Read coding sheet

```{r coding}
the_sheet <- "https://docs.google.com/spreadsheets/d/1OOXB-8Uk-fh_urw0Lm4DC0jBueXLIb4Bm-a9--UVXOw/edit?usp=sharing"

coding <- read_sheet(the_sheet) %>%
  mutate(
    outcome = factor(outcome, levels = c("duration", "f0", "formants", "intensity", "harmonics", "SNR", "multivariate", "other")),
    temporal_window = factor(temporal_window, levels = c("segment", "syllable", "word", "phrase", "sentence", "other"))
  )

```

# Download OSF components

First, we get a list of the OSF components in the Teams Analyses component. (It takes a few seconds)

```{r comps}
assigned <- coding %>%
  select(team, animal, assigned_to) %>%
  distinct()

comps <- osf_retrieve_node("https://osf.io/n3fyd/") %>%
  osf_ls_nodes(n_max = Inf) %>%
  left_join(y = assigned, by = c("name" = "animal"))
```

Now we get only those components that are assigned to you. Tell me who you are when prompt.

```{r who}
who <- menu(c("Ste", "Joseph", "Timo"), "Who are you?")

whos <- c("sc", "jvc", "tr")
your_comps <- comps %>%
  filter(assigned_to == whos[who])
dir.create(glue("./data/analyses/{whos[who]}"), showWarnings = FALSE, recursive = TRUE)
```

And now we download the components in `data/analyses/`

```{r download}
for (comp in 1:nrow(your_comps)) {
  name <- your_comps$name[comp]
  files <- osf_ls_files(your_comps[comp,], n_max = Inf)
  dir <- glue("./data/analyses/{whos[who]}/{name}")
  dir.create(dir, showWarnings = FALSE, recursive = TRUE)
  cli_h1(name)
  osf_download(
    files,
    path = dir,
    recurse = TRUE,
    conflicts = "skip",
    verbose = TRUE, progress = TRUE
  )
}
```

# Refit models

Now that the components have been downloaded, we can refit the models using the scripts in `scripts/r/04-refit/`.

Once all your models have been refitted, you can upload them to the OSF, in the Cache component, `models/refitted/` folder.

Here's some code that does that for you.

```{r upload-refitted}
cache <- osf_retrieve_node("wds2m")
refitted <- osf_ls_files(osf_ls_files(cache, type = "folder")) %>%
  filter(name == "refitted")
models <- list.files(
  "./data/analyses/models",
  full.names = TRUE
)

osf_upload(
  refitted,
  path = models,
  recurse = TRUE, conflicts = "skip", progress = TRUE, verbose = TRUE
)
```


# Get estimated from refitted models

We first download all the refitted models .rds files from the OSF

```{r download-refitted}
cache <- osf_retrieve_node("wds2m")
refitted_rds <- osf_ls_files(cache, "models/refitted", n_max = Inf)

osf_download(
  refitted_rds,
  path = "./data/analyses/models/",
  conflicts = "skip", progress = TRUE, verbose = TRUE
)
```


A few helpers. 

```{r helpers}
# Plotting theme because Im extra
clean_theme <- function(...) {
  list(
    theme_minimal(), 
    theme(
      axis.title.y = element_text(size = rel(.9), hjust = 0.95),
      axis.title.x = element_text(size = rel(.9), hjust = 0.95),
      panel.grid.major = element_line(colour = 'grey90', size = 0.15),
      panel.grid.minor = element_line(colour = 'grey90', size = 0.15))
  )
}

# Functional sequence to get relevant info from Rds files
clean_up <- . %>% 
  tidy(effects = "fixed") %>% 
  suppressWarnings() %>% 
  filter(term %in% c("effect_cattypical", "effect_con")) %>% 
  select(term, estimate, se = std.error)
```

```{r load-models}
msa_models <- dir_ls(path = here("data/analyses/models"), regexp = ".rds$") %>% 
  as_tibble() %>% 
  transmute(path = value,
    mod_name = str_remove(path, here("data/analyses/models/")), 
    mod_name = str_remove(mod_name, ".rds"), 
    model = map(path, ~ readRDS(file = .))) %>% 
  separate(mod_name, 
    into = c("word1", "word2", "mod_n", "outcome", "typicality"), 
    sep = "_", remove = F) %>% 
  unite(group, word1, word2, sep = "_") %>% 
  select(group, mod_name:model) %>% 
  mutate(sum = map(model, clean_up)) %>% 
  suppressWarnings() # because it warns every time that some coef have underscores and its annoying
```

```{r effect-table}
# Simple pandoc table of the models, estimates, se, etc.
msa_models %>% 
  unnest(sum) %>% 
  select(-model) %>% 
  knitr::kable(format = "pandoc")
```

```{r forest-plot}
# Simple forest plot of the estimates +/- SE
msa_models %>% 
  unnest(sum) %>% 
  mutate(
    typicality_lab = if_else(
      typicality == "cat", "Typicality = categorical", "Typicality = continuous"
    ), 
    mod_name = fct_reorder(mod_name, estimate)
  ) %>% 
  ggplot(aes(x = estimate, y = mod_name)) + 
  geom_vline(xintercept = 0) +
  geom_segment(aes(x = estimate - se, xend = estimate + se, yend = mod_name), 
    color = "#cc0033", alpha = 0.5, size = 3, lineend = "round") + 
  geom_point(color = "#cc0033", pch = 21, stroke = 3, size = 3.1) +
  facet_wrap(~ typicality_lab, ncol = 1, scales = "free") +
  labs(y = "Model", x = "Estimate Â± SE") + 
  clean_theme() + 
  theme(strip.text.x = element_text(hjust = 0))
```

# Analyses coding plots

```{r}
coding %>%
  ggplot(aes(model)) +
  geom_bar()
```

```{r}
coding %>%
  drop_na(outcome, temporal_window) %>%
  ggplot() +
  geom_mosaic(aes(x = product(outcome, temporal_window), fill = outcome))
```

```{r}
coding %>%
  drop_na(outcome, temporal_window) %>%
  filter(
    outcome %in% c("duration", "f0", "intensity"),
    temporal_window %in% c("segment", "word", "phrase", "sentence")
  ) %>%
  droplevels() %>%
  ggplot() +
  geom_mosaic(aes(x = product(outcome, temporal_window), fill = outcome))
```

```{r}
coding %>%
  drop_na(outcome, operationalisation) %>%
  filter(
    outcome %in% c("duration", "f0", "intensity"),
    temporal_window %in% c("segment", "word", "phrase", "sentence")
  ) %>%
  droplevels() %>%
  ggplot() +
  geom_mosaic(aes(x = product(outcome, operationalisation), fill = outcome))
```

```{r}
coding %>%
  select(framework:operationalisation, temporal_window, typicality_operationalization, random_effects) %>%
  distinct()
```

```{r}
coding %>%
  select(team, n_models) %>%
  distinct() %>%
  drop_na() %>%
  summarise(mean(n_models), median(n_models), sd(n_models), min(n_models), max(n_models))
```

