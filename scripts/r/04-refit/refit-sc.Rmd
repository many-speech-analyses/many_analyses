---
title: "Re-fit"
subtitle: "SC"
output: html_document
date: "Last update: `r Sys.Date()`"
---

```{r setup}
knitr::opts_knit$set(root.dir = here::here())
library(tidyverse)
library(plyr)
library(brms)
```


# dermatolepis_aculeatus

```{r}
msa_data <- read_csv("./data/analyses/sc/dermatolepis_aculeatus/Many Speech Analyses_measurements.csv") %>%
  mutate(
    effect_cat = factor(typicality, levels = c("atypical", "medium", "typical")),
    adj_pitch_max.norms = scale(adj_pitch_max) %>% as.numeric(),
    noun_pitch_max.norms= scale(noun_pitch_max) %>% as.numeric(),
    phrase_pitch_max.norms= scale(phrase_pitch_max) %>% as.numeric()
  ) %>%
  filter(
    exclude == "N",
    condition == "NF"
  ) %>%
  drop_na()
```

```{r}
# LME  noun model with one fixed effect, two random effects: speaker, noun
dermatolepis_aculeatus_1_pitch_cat <- brm(
  noun_pitch_max.norms ~ effect_cat + (1 | speaker) + (1 | noun),
  data = msa_data,
  cores = 4,
  threads = threading(2, grainsize = 100), 
  backend = "cmdstanr",
  file = "./data/analyses/models/dermatolepis_aculeatus_1_pitch_cat"
)

# LME  adjective model with one fixed effect, two random effects: speaker, adjective
dermatolepis_aculeatus_2_pitch_cat <- brm(
  adj_pitch_max.norms ~ effect_cat + (1 | speaker) + (1 | adjective),
  data = msa_data,
  cores = 4,
  threads = threading(2, grainsize = 100), 
  backend = "cmdstanr",
  file = "./data/analyses/models/dermatolepis_aculeatus_2_pitch_cat"
)

# LME  phrase model with one fixed effect, two random effects: speaker, phrase
dermatolepis_aculeatus_3_pitch_cat <- brm(
  phrase_pitch_max.norms ~ effect_cat + (1 | speaker) + (1 | phrase),
  data = msa_data,
  cores = 4,
  threads = threading(2, grainsize = 100), 
  backend = "cmdstanr",
  file = "./data/analyses/models/dermatolepis_aculeatus_3_pitch_cat"
)
```

# epinephelus_aztecus

Lavaan.

# eriphia_laterispinis

```{r}
# listing all available csv files (30 participants in the production study)
trials_files <- list.files(
    path = "./osf/data/production/trial-lists/",
    pattern = ".csv", full.names = TRUE
    )

# importing and reshaping all csv files at once
trials <- map_dfr(
    .x = trials_files,
    .f = read.csv
    )

msa_data <- read.csv("data/analyses/sc/eriphia_laterispinis/processed_data/summary_data.csv") %>%
    # keeping only the NF condition
    filter(Condition == "NF") %>%
    # retrieving the trial information
    left_join(x = ., y = trials, by = c("speaker", "trial") ) %>%
    # keeping only the relevant columns
    select(
        speaker, trial, condition,
        mean_f0, mean_int, duration,
        typicality, typ_mean, typ_sd, typ_median
        ) %>%
    # normalising measures per speaker
    group_by(speaker) %>%
    mutate(
        mean_f0 = scale(mean_f0) %>% as.numeric(),
        mean_int = scale(mean_int) %>% as.numeric(),
        duration = scale(duration) %>% as.numeric()
        ) %>%
    # un-grouping
    ungroup() %>%
    # filtering out medium typical items
    filter(typicality != "medium")  %>%
    # converts to factor
    mutate(effect_cat = factor(x = typicality, levels = c("atypical", "typical")))
```

```{r}
priors <- c(
    prior(normal(0, 1), class = Intercept),
    prior(normal(0, 1), class = b),
    prior(exponential(0.1), class = sd, resp = "duration"),
    prior(exponential(0.1), class = sigma, resp = "duration"),
    prior(exponential(0.1), class = sd, resp = "meanf0"),
    prior(exponential(0.1), class = sigma, resp = "meanf0"),
    prior(exponential(0.1), class = sd, resp = "meanint"),
    prior(exponential(0.1), class = sigma, resp = "meanint")
    )

# fitting the varying intercept model
# 4 chains with each 8000 post warm-up posterior samples
eriphia_laterispinis_1_mult_cat <- brm(
  bf(mvbind(mean_f0, mean_int, duration) ~
    1 + effect_cat + (1 | speaker) ) +
    set_rescor(rescor = TRUE),
  prior = priors,
  data = msa_data,
  cores = 4,
  threads = threading(2, grainsize = 100), 
  backend = "cmdstanr",
  file = "data/analyses/models/eriphia_laterispinis_1_mult_cat"
)
```

# genyonemus_evotis

# hoplostethus_macrosteus

```{r}
msa_data <- read_csv("./data/analyses/sc/hoplostethus_macrosteus/Analysis materials/Results_clean.csv") %>%
  mutate(
    effect_cat = factor(typicality, levels = c("atypical", "medium", "typical")),
    color = factor(color),
    durmsec = scale(durmsec) %>% as.numeric(),
    intensity_maximum = scale(intensity_maximum) %>% as.numeric()
  )

contrasts(msa_data$color) <- "contr.sum"
```

```{r}
hoplostethus_macrosteus_1_dur_cat <- brm(
  durmsec ~ Observation + effect_cat + color + (1|Participant),
  data = msa_data,
  cores = 4,
  threads = threading(2, grainsize = 100), 
  backend = "cmdstanr",
  file = "data/analyses/models/hoplostethus_macrosteus_1_dur_cat"
)

hoplostethus_macrosteus_2_int_cat <- brm(
  intensity_maximum ~ Observation + effect_cat + color + (1|Participant),
  data = msa_data,
  cores = 4,
  threads = threading(2, grainsize = 100), 
  backend = "cmdstanr",
  file = "data/analyses/models/hoplostethus_macrosteus_2_int_cat"
)
```

# neosilurus_omanensis

Script missing.

```{r}

```

# paralichthys_undulatus

```{r}
msa_data <- read_delim("./data/analyses/sc/paralichthys_undulatus/Data files/MSA-measurements.txt", delim = "\t") %>%
  mutate(
    Typicality = recode(Typicality, atyp = "atypical", med = "medium", typ = "typical"),
    effect_cat = factor(Typicality, levels = c("atypical", "medium", "typical")),
    Word.type = factor(Word.type),
    RangeST = scale(RangeST) %>% as.numeric()
  )

contrasts(msa_data$Word.type) <- "contr.sum"
```

```{r}
paralichthys_undulatus_1_f0_cat <- brm(
  RangeST ~ Word.type + Typicality + (1|Speaker) + (1|Word),
  data = msa_data,
  cores = 4,
  threads = threading(2, grainsize = 100), 
  backend = "cmdstanr",
  file = "data/analyses/models/paralichthys_undulatus_1_f0_cat"
)
```

# petauroides_fistulator

GAM but team reported parametric effects so we could include those.

# polymetme_brevirostrum

```{r}
# Get datasets
praat_data <- read_delim("./data/analyses/sc/polymetme_brevirostrum/Data/acoustic_results.txt", delim = "\t")
norming_data <- read_csv("./data/analyses/sc/polymetme_brevirostrum/Data/ratings_summary.csv")
ratings <- read_csv("./osf/data/norming/ratings/ratings.csv")
foods <- list('aprikose','kirsche','moehre','gurke','erbsen','tomate','kartoffeln','banane','zitrone','bohnen','erdbeere','mandarine','walnuss')
# Get rid of that pesky case marking and include typicality bins
msa_data <- norming_data %>%
  filter(colour %in% list('braun','gelb','gruen','rot','orange')) %>% 
  mutate(
    object = tolower(object),
    Typicality = case_when(
      typ_median >= 90 ~ "typical",
      typ_median < 25 ~ "atypical",
      typ_median >= 25 & typ_median < 90 ~ "medium"
    ),
    colour = recode(colour, "braun"="braunen", "gelb"="gelben", "gruen"="gruenen", "rot"="roten", "orange"="orangen")
  ) %>%
  right_join(., praat_data, by = c("colour"="Adjective", "object"="Noun")) %>%
  filter(is.na(Notes)) %>%
  mutate(
    across(contains("f0"), function(x) {ifelse(x == "--undefined--", NA, x)}),
    Category = ifelse(object %in% foods, "FOOD", "NONFOOD"),
    effect_cat = factor(Typicality, levels = c("atypical", "medium", "typical")),
    Adj_Dur = scale(Adj_Dur) %>% as.numeric(),
    Condition = factor(Condition),
    Category = factor(Category)
  )

contrasts(msa_data$Category) <- "contr.sum"
contrasts(msa_data$Condition) <- "contr.sum"
```

100% divergent transitions.

```{r}
polymetme_brevirostrum_1_dur_cat <- brm(
  Adj_Dur ~ Condition * effect_cat * Category + (Condition * effect_cat || Speaker) + (Condition || object) + (effect_cat || colour),
  data = msa_data,
  cores = 4,
  threads = threading(2, grainsize = 100), 
  backend = "cmdstanr",
  file = "data/analyses/models/polymetme_brevirostrum_1_dur_cat"
)
```

# saron_pictus

```{r}
# The following code reads in the thirty different .csv files with the trial-level data and merges them into a single dataframe
trial_dat <- list.files(path = "./osf/data/production/trial-lists/",
                       pattern = "*.csv",
                       full.names = TRUE) %>%
  lapply(read_csv) %>%                              
  bind_rows

# Reading in the results file output by the Praat script
d <- read.delim("./data/analyses/sc/saron_pictus/results.txt",
                fileEncoding = "UTF-16")

# Saving original number of rows
N <- nrow(d)

# Getting rid of columns we won't need from trial_dat
trial_dat <- trial_dat[trial_dat$condition == "NF",]

# Changing the trial_dat colours to the inflected forms to match the utterances
trial_dat$target_colour[trial_dat$target_colour == "gelb"] <- "gelben"
trial_dat$target_colour[trial_dat$target_colour == "orange"] <- "orangen"
trial_dat$target_colour[trial_dat$target_colour == "braun"] <- "braunen"
trial_dat$target_colour[trial_dat$target_colour == "rot"] <- "roten"
trial_dat$target_colour[trial_dat$target_colour == "gruen"] <- "gruenen"

# Saving the target colours present in the data-set into a vector
colours <- c("gelben", "orangen", "braunen", "roten", "gruenen")

# Subsetting to only target nouns and adjectives
d <- d[d$word_label %in% trial_dat$target_name | d$word_label %in% trial_dat$target_colour,]
d <- droplevels(d)

# Merging the data from Praat with the trial data
d <- merge(d, trial_dat, 
            by = c("speaker", "trial", "condition"))

# Lumping all trial problems together
d$trial_status <- ifelse(d$notes == "", "Good", "Bad")

# Creating a column specifying whether a word is an adjective or noun
d$word_class <- ifelse(d$word_label %in% colours, "adjective", "noun")

# Creating a column with duration in milliseconds instead of seconds
d$dur_ms <- d$word_duration*1000

# Transforming trial to have a max value of 1
d$trial_minmax <- (d$trial - min(d$trial)) / (max(d$trial) - min(d$trial))

# Creating a data-set that is only adjectives
adj <- d[d$word_class == "adjective",]

# Removing trials with problems
adj <- adj[adj$notes == "",]
adj$effect_cat <- factor(adj$typicality,
                         levels = c("atypical", "medium", "typical"))

adj <- adj %>%
  mutate(
    trial_minmax = scale(trial_minmax) %>% as.numeric(),
    dur_ms = scale(log(dur_ms)) %>% as.numeric()
  )

model_formula <- bf(dur_ms ~
                      effect_cat +
                      trial_minmax +
                      (effect_cat + trial_minmax | speaker) +
                      (effect_cat + trial_minmax | word_label))

# Setting weakly-informative priors for lognormal model
lognormal_priors <- c(
  prior(normal(5.5, 1), class = "Intercept"),
  prior(normal(0, 0.5), class = "b"),
  prior(normal(0, 1), class = "sd"),
  prior(normal(0, 1), class = "sigma"),
  prior(lkj(2), class = "cor")
)

# Fitting the lognormal model to data
saron_pictus_1_dur_cat <- brm(
  model_formula,
  data = adj,
  family = gaussian,
  prior = lognormal_priors,
  backend = "cmdstanr",
  control = list(adapt_delta = 0.99, max_treedepth = 12),
  cores = 4,
  threads = threading(2, grainsize = 100), 
  file = "data/analyses/models/saron_pictus_1_dur_cat"
)
```


# stygobromus_tyraica

ML.

# swiftia_ruber

Bayesian B-splines.

# trachurus_riukiuensis

```{r}
#Read in output file from Praat script
msa <- read.delim("./data/analyses/sc/trachurus_riukiuensis/MSA-Praat-output.txt", na.strings = "--undefined--")

#Read in list of NF trials (this is an edited version of one of the trial-lists on OSF)
triallist <- read.csv("./data/analyses/sc/trachurus_riukiuensis/MSA-triallist.csv")

#Merge them together
msa2 <- merge(msa, triallist, by=c("noun","condition"))
#Adjust factor
msa2$comment <- as.factor(msa2$comment)
#Remove errors (31/900) and hesitation utterances (20/900) ~ 6% of data removed
data <- subset(msa2, comment=="NA" | comment=="noise")

#Remove JW_3; too many errors and hesitations
data <- subset(data, participant!="JW_3")

#Adjust typicality variable as dummy coded factor
data$effect_cat <- factor(data$typicality, levels = c("atypical", "medium", "typical"))

#Calculate a by participant median for each f0 measure and the median absolute deviation
#See Leys, C., Ley, C., Klein, O., Bernard, P., & Licata, L. (2013). Detecting outliers: Do not use standard deviation around the mean, use absolute deviation around the median. Journal of Experimental Social Psychology, 49(4), 764-766.
by.participant.median <- data %>%
  group_by(participant) %>%
  dplyr::summarise( n.mad = mad(noun_peakf0), n.median = median(noun_peakf0),
             adj.mad = mad(adj_peakf0), adj.median = median(adj_peakf0),
             art.mad = mad(art_peakf0), art.median = median(art_peakf0),)

#Merge by participant with full data
data.mm <- merge(by.participant.median, data)

#Create new dataframes for each f0 measure by removing less than 2.5 times median absolute deviation
noun <- subset(data.mm, noun_peakf0 > n.median-(2.5*n.mad))
#noun peak f0 removed 28 data points

adjective <- subset(data.mm, adj_peakf0 > adj.median-(2.5*adj.mad))
#adj peak f0 removed 14 data points

article <- subset(data.mm, art_peakf0 > art.median-(2*art.mad))
#art peak f0 removed 160 data points NOTE we use 2 times median absolute deviation to remove all creaky voice tokens

# scale
data <- data %>%
  mutate(
    art_dur = scale(art_dur) %>% as.numeric(),
    adj_dur = scale(adj_dur) %>% as.numeric()
  )

article <- article %>%
  mutate(
    art_peakf0 = scale(art_peakf0) %>% as.numeric()
  )

adjective <- adjective %>%
  mutate(
    adj_peakf0 = scale(adj_peakf0) %>% as.numeric()
  )

noun <- noun %>%
  mutate(
    noun_peakf0 = scale(noun_peakf0) %>% as.numeric()
  )
```

```{r}
trachurus_riukiuensis_1_durart_cat <- brm(
  art_dur ~ effect_cat + (1 | participant) + (1 | noun),
  data = data,
  backend = "cmdstanr",
  cores = 4,
  threads = threading(2, grainsize = 100), 
  file = "data/analyses/models/trachurus_riukiuensis_1_durart_cat"
)

trachurus_riukiuensis_2_f0art_cat <- brm(
  art_peakf0 ~ effect_cat + (1 | participant),
  data = article,
  backend = "cmdstanr",
  cores = 4,
  threads = threading(2, grainsize = 100), 
  file = "data/analyses/models/trachurus_riukiuensis_2_f0art_cat"
)

trachurus_riukiuensis_3_duradj_cat <- brm(
  adj_dur ~ effect_cat + (1|participant) + (1|noun),
  data = data,
  backend = "cmdstanr",
  cores = 4,
  threads = threading(2, grainsize = 100), 
  file = "data/analyses/models/trachurus_riukiuensis_3_duradj_cat"
)

trachurus_riukiuensis_4_f0adj_cat <- brm(
  adj_peakf0 ~ effect_cat + (1|participant) + (1|noun),
  data = adjective,
  backend = "cmdstanr",
  cores = 4,
  threads = threading(2, grainsize = 100), 
  file = "data/analyses/models/trachurus_riukiuensis_4_f0adj_cat"
)

trachurus_riukiuensis_5_f0noun_cat <- brm(
  noun_peakf0 ~ effect_cat + (1|participant) + (1|noun),
  data = noun,
  backend = "cmdstanr",
  cores = 4,
  threads = threading(2, grainsize = 100), 
  file = "data/analyses/models/trachurus_riukiuensis_5_f0noun_cat"
)
```


# varanus_eulophotes

```{r}
# reading in data
f0data <- read.csv("./data/analyses/sc/varanus_eulophotes/analysis/f0data-complete.csv", header = T)

# new dataframe with only typicality-rated data
f0data_cor <- f0data[f0data$typicality !="NA" & !is.na(f0data$typicality),]
f0data_cor$avgF0 <- as.numeric(f0data_cor$avgF0) # coercing types...
f0data_cor$effect_cat <- factor(f0data_cor$typicality, levels = c("atypical", "medium", "typical"))

##### DESCRIPTIVE STATS and GRAPHS ###########
# centering f0 values within speakers
f0data_cor <- ddply(f0data_cor, c("speaker"), transform, centeredF0 = scale(avgF0, scale=F)) # centered
f0data_cor <- ddply(f0data_cor, c("speaker"), transform, scaledF0 = scale(avgF0)) # z-scores
```

```{r}
varanus_eulophotes_1_f0_cat <- brm(
  scaledF0 ~ effect_cat + (1|speaker),
  data = f0data_cor,
  backend = "cmdstanr",
  cores = 4,
  threads = threading(2, grainsize = 100), 
  file = "data/analyses/models/varanus_eulophotes_1_f0_cat"
)
```

