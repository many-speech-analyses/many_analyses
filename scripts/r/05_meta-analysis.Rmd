---
title: "05 - Meta-analysis"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
library(tidyverse)
library(brms)
library(tidybayes)
library(faux)
library(betapart)
library(modelr)
library(ggdist)
library(patchwork)
library(ggcorrplot)

my_seed <- 99
set.seed(my_seed)
b4ss_colors <- c(purple = "#8970FF", orange = "#FFA70B", pink = "#dd1c77")
```

# Read data

Here we read the `msa_models.rds` file which contains the estimates and standard errors obtained from refitting the analyses submitted by the teams.

```{r msa-models}
msa_models <- readRDS("./data/analyses/msa_models.rds") %>%
  mutate(
    outcome = as.factor(outcome),
    typicality = as.factor(typicality),
    temporal_window = as.factor(temporal_window)
  ) %>%
  droplevels() %>%
  mutate(
    outcome = contr_code_sum(outcome),
    typicality = contr_code_sum(typicality),
    temporal_window = contr_code_sum(temporal_window)
  )

# bpair <- tibble::tibble(preds) %>% tidyr::unnest_wider(preds, names_sep = ".") %>%
#     as.matrix() %>%
#     betapart::beta.pair(.)
#   sdim <- as.matrix(bpair$beta.sor)
#   diag(sdim) <- NA
#   rowSums(sdim, na.rm = T) / length(preds)
```

# Meta-analysis

```{r meta-bm}
priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(cauchy(0, 1), class = sd)
)

meta_bm <- brm(
  estimate | se(se) ~ (1 | model_id),
  data = msa_models,
  prior = priors,
  chain = 4,
  seed = my_seed,
  cores = 4,
  backend = "cmdstanr",
  threads = threading(2),
  file = "./data/meta_analysis/meta_bm.rds"
)
```

```{r meta-bm-summary} 
meta_bm
```

```{r post-meta}
post_meta <- meta_bm %>%
  spread_draws(b_Intercept, r_model_id[model,]) %>%
  mutate(model_mean = b_Intercept + r_model_id) %>%
  
  group_by(model) %>% 
  
  dplyr::summarise(
    post_mean = mean(model_mean),
    lower95 = quantile(model_mean, probs = .025),
    higher95 = quantile(model_mean, probs = .975)
  ) %>%
  # This needs to be fed by whether or not the authors considered there to be an effect
  mutate(
    compelling = as.factor(
      case_when(
        lower95 > 0 ~ "negative", higher95 < 0 ~ "positive",
        TRUE ~ "not compelling"
      )
    )
  )

# Extract mean and CrIs of each model
population_mean = fixef(meta_bm)[1,1]
population_lower95 = fixef(meta_bm)[1,3]
population_higher95 = fixef(meta_bm)[1,4]
```

```{r meta-plot-1}
post_meta %>%
  ggplot(aes(x = reorder(model, post_mean), y = post_mean, colour = compelling)) +
  geom_hline(yintercept = 0, lty = "dotted") +
  geom_point(size = 0.5) +
  geom_errorbar(aes(ymin = lower95, ymax = higher95), width = 0) +
  scale_y_continuous(limits = c(-0.5, 1), breaks = c(-0.5, 0, 0.5, 1)) + 
  annotate("text", x = c(30, 90, 150), y = 0.8,
           hjust = c(0, 0.5, 1),
           color = c(b4ss_colors[[2]], "black", b4ss_colors[[1]]),
           label = c("Negative (95% CrI)", "Not compelling", "Positive (95% CrI)")
           ) +
  labs(x = "Submitted statistical models", y = "Standardized posterior effect size") +
  scale_color_manual(values = c(b4ss_colors[[1]], "black", b4ss_colors[[2]])) + 
  theme_classic() +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line = element_blank()
        )

ggsave(filename = "figs/meta_plot1.png",
       device = "png",
       width = 200, 
       height = 75,
       units = "mm", 
       dpi = 500)
```

```{r meta-plot-2}
# alternative visualization with absolute values
post_meta_abs <- post_meta %>% 
  mutate(post_mean_abs = case_when(post_mean > 0 ~ post_mean,
                                   post_mean < 0 ~ abs(post_mean)),
         low_to_mean = post_mean - lower95,
         mean_to_high = higher95 - post_mean,
         l95_abs = post_mean_abs - low_to_mean,
         h95_abs = post_mean_abs + mean_to_high,
         compelling_abs = case_when(compelling == "negative" ~ "positive",
                                    compelling == "positive" ~ "positive",
                                    compelling == "not compelling" ~ "not compelling")
         )


ggplot(post_meta_abs,
       aes(x = reorder(model, post_mean_abs), 
             y = post_mean_abs, 
             colour = compelling_abs)) +
  geom_hline(yintercept = 0,
             lty = "dotted") +
  geom_point(size = 0.5) +
  geom_errorbar(aes(ymin = l95_abs,
                    ymax = h95_abs),
                 width = 0) +
  scale_y_continuous(limits = c(-0.5, 1),
                     breaks = c(-0.5, 0, 0.5, 1)) + 
  annotate("text",
           x = c(60,120),
           y = 0.8,
           hjust = c(0.5, 0.5),
           color = c("black", b4ss_colors[[3]]),
           label = c("Not compelling",
                     "Claimed effect")
           ) +
  labs(x = "submitted statistical models",
       y = "abs(standardized posterior effect size)\n") +
  scale_color_manual(values = c("black", b4ss_colors[[3]])) + 
  theme_classic() +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line = element_blank()
        )

ggsave(filename = "figs/meta_plot2.png",
       device = "png",
       width = 200, 
       height = 75,
       units = "mm", 
       dpi = 500)

```

## Include nested effects

```{r meta-bm-nest}
priors_nest <- c(
  prior(normal(0, 1), class = Intercept),
  prior(cauchy(0, 1), class = sd)
)

meta_bm_nest <- brm(
  estimate | se(se) ~ (1 | animal) + (1 | animal:model_id),
  data = msa_models,
  prior = priors_nest,
  chain = 4,
  seed = my_seed,
  cores = 4,
  backend = "cmdstanr",
  threads = threading(2),
  control = list(adapt_delta = 0.999),
  file = "./data/meta_analysis/meta_bm_nest.rds"
)

meta_bm_nest
```

```{r post-meta-nest}
post_meta_nest <- meta_bm_nest %>%
  spread_draws(b_Intercept, `r_animal:model_id`[model,]) %>%
  mutate(model_mean = b_Intercept + `r_animal:model_id`) %>%
  
  group_by(model) %>% 
  
  dplyr::summarise(
    post_mean = mean(model_mean),
    lower95 = quantile(model_mean, probs = .025),
    higher95 = quantile(model_mean, probs = .975)
  ) %>%
  # This needs to be fed by whether or not the authors considered there to be an effect
  mutate(
    compelling = as.factor(
      case_when(
        lower95 > 0 ~ "negative", higher95 < 0 ~ "positive",
        TRUE ~ "not compelling"
      )
    )
  )

# Extract mean and CrIs of each model
population_mean_nest = fixef(meta_bm_nest)[1,1]
population_lower95_nest = fixef(meta_bm_nest)[1,3]
population_higher95_nest = fixef(meta_bm_nest)[1,4]
```

```{r merged}
# merge dataset and model output (awkward)
merged <- 
  post_meta_nest %>%
  #rename(model = model) %>% 
  separate(model, sep = "_", into = c("t1","t2","t3","t4","t5", "t6", "t7", "t8")) %>% 
  mutate(model_id = ifelse(is.na(t8) & is.na(t7) & is.na(t6),
                           paste0(t3, "_", t4, "_", t5),
                           ifelse(is.na(t8) & is.na(t7),
                                  paste0(t3, "_", t4, "_", t5, "_", t6),
                                  ifelse(is.na(t8),
                                         paste0(t3, "_", t4, "_", t5, "_", t6, "_", t7),
                                         paste0(t3, "_", t4, "_", t5, "_", t6, "_", t7, "_", t8)
                )))) %>% 
  select(-c("t1","t2","t3","t4","t5", "t6", "t7", "t8")) %>% 
  full_join(msa_models) %>% 
  mutate(lowerCI = estimate - 1.96*se,
         higherCI = estimate + 1.96*se,
         compelling_raw = as.factor(
           case_when(
            lowerCI > 0 ~ "negative", higherCI < 0 ~ "positive",
            TRUE ~ "not compelling"
            )
         ))
```

```{r meta-shrinkage}
#meta_shrinkage <- 
  ggplot(data = merged,
    aes(x = reorder(model_id, post_mean), y = post_mean, colour = compelling)) +
  geom_hline(yintercept = 0, lty = "dotted") +
  geom_point(aes(y = estimate),
             size = 0.8,
             pch = 17,
             fill = "black",
             alpha = 0.2) +
  geom_segment(aes(xend = reorder(model_id, post_mean), 
                   y = estimate - 1.96*se, 
                   yend = estimate + 1.96*se),
                lineend = "round",
                size = 1.1,
                width = 0,
                color = "black",
                alpha = 0.2) +
  geom_point(size = 0.5) +
  geom_errorbar(aes(ymin = lower95, ymax = higher95), 
                width = 0) +
  scale_x_discrete(expand =  c(0.05,0.05)) + 
  scale_y_continuous(limits =  c(-2, 2.2)) + 
  annotate("text", x = c(5,5), y = c(1.8,2.1),
           size = 3,
           hjust = 0,
           color = c("#ef8a62", "black"),
           label = c("Not compelling = 95% CrI includes 0", "Compelling = 95% CrI does not includes 0")
           ) +
    annotate("segment", 
             x = c(0.5,0.5), y = c(1.75,2.05),
             xend = c(0.5,0.5), yend = c(1.85,2.15),
           size = 2.5,
           hjust = 0,
           color = c("black", "#ef8a62"),
           label = c("95% CrI includes 0", "95% CrI does not includes 0")
           ) +
  labs(# title = "Effect estimates across all submitted effects",
       caption = "Raw estimates extracted from teams' models (grey),\nshrunken estimates from meta-analytical model (black/orange)\n",
       x = "Submitted typicality effect", 
       y = "Standardized posterior effect size\n") +
  scale_color_manual(values = c("#ef8a62","black","#ef8a62")) + 
  theme_classic() +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line = element_blank(),
        plot.caption = element_text(vjust = -5)
        )

ggsave(filename = "figs/meta_plot1_shrinkage.png",
       plot = meta_shrinkage,
       device = "png",
       width = 150, 
       height = 85,
       units = "mm", 
       dpi = 500)
```

```{r meta-raw}
meta_raw <- 
  ggplot(data = merged,
    aes(x = reorder(model_id, estimate), 
        y = estimate,
        color = compelling_raw)) +
  geom_hline(yintercept = 0, lty = "dotted") +
  geom_errorbar(aes(x = reorder(model_id, estimate),
                    ymin = estimate - 1.96*se, 
                    ymax = estimate + 1.96*se), 
                alpha = 0.5,
                width = 0) +
  geom_point(size = 0.5) +
  annotate("text", x = c(30, 90, 150), y = 2,
           hjust = c(0, 0.5, 1),
           color = c(b4ss_colors[[2]], "black", b4ss_colors[[1]]),
           label = c("Negative (95% CI)", "Not compelling", "Positive (95% CI)")
           ) +
  labs(x = "Submitted typicality effect", 
       y = "Standardized posterior effect size\n") +
  scale_color_manual(values = c(b4ss_colors[[1]], "black", b4ss_colors[[2]])) + 
  theme_classic() +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line = element_blank()
        )

ggsave(filename = "figs/meta_plot1_raw.png",
       plot = meta_raw,
       device = "png",
       width = 200, 
       height = 75,
       units = "mm", 
       dpi = 500)
```

# Analytic and researcher-related predictors model

Weakly-informative regularising priors.

```{r preds-priors}
preds_priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 1), class = b)
)
```

```{r predictors-bm}
msa_models <- msa_models %>% 
  mutate(
    pop_sdi_s = (pop_sdi - mean(pop_sdi, na.rm = TRUE)) / sd(pop_sdi,  na.rm = TRUE),
    n_random_s = (n_random - mean(n_random, na.rm = TRUE)) / sd(n_random,  na.rm = TRUE),
    n_models_s = (n_models - mean(n_models, na.rm = TRUE)) / sd(n_models,  na.rm = TRUE),
    all_rating_s = (all_rating - mean(all_rating, na.rm = TRUE)) / sd(all_rating,  na.rm = TRUE),
    years_from_phd_s = (years_from_phd - mean(years_from_phd, na.rm = TRUE)) / sd(years_from_phd,  na.rm = TRUE),
    prior_belief_s = (prior_belief - mean(prior_belief, na.rm = TRUE)) / sd(prior_belief,  na.rm = TRUE)
  ) 

predictors_bm_rintercepts <- brm(
  estimate | se(se) ~
    pop_sdi_s +
    n_models_s +
    outcome +                  # major dimension
    temporal_window +          # temporal window
    typicality +
    all_rating_s +
    years_from_phd_s +
    prior_belief_s +
    (1 | animal),
  data = msa_models,
  prior = preds_priors,
  chain = 4,
  iter = 4000,
  control = list(adapt_delta = 0.9, max_treedepth = 13),
  seed = my_seed,
  cores = 4,
  threads = threading(2),
  backend = "cmdstanr",
  file = "./data/meta_analysis/predictors_bm_rintercepts.rds"
)

predictors_bm_rintercepts
```


```{r post-pred}
post_pred <- predictors_bm_rintercepts %>%
  spread_draws(b_Intercept, 
               b_outcome.durationMintercept,
               b_outcome.f0Mintercept,
               b_outcome.formantsMintercept,
               b_outcome.intensityMintercept,
               b_temporal_window.segmentMintercept,
               b_temporal_window.wordMintercept,
               b_temporal_window.phraseMintercept,
               b_temporal_window.sentenceMintercept,
               b_typicality.categoricalMintercept,
               b_pop_sdi_s,
               b_n_models_s,
               b_all_rating_s,
               b_years_from_phd_s,
               b_prior_belief_s
               ) %>%
  select(-.chain, -.iteration) %>% 
  pivot_longer(-.draw, names_to = "predictor", values_to = "posterior") %>% 
  mutate(predictor = fct_recode(
    predictor, 
    "Intercept" = "b_Intercept",
    "duration" = "b_outcome.durationMintercept", 
    "f0" = "b_outcome.f0Mintercept", 
    "intensity" = "b_outcome.intensityMintercept",
    "formants" = "b_outcome.formantsMintercept",
    "segment" = "b_temporal_window.segmentMintercept",
    "word" = "b_temporal_window.wordMintercept",
    "phrase" = "b_temporal_window.phraseMintercept",
    "sentence" = "b_temporal_window.sentenceMintercept",
    "model uniqueness" = "b_pop_sdi_s",
    "team's number of models"  = "b_n_models_s",
    "typicality operationalization" = "b_typicality.categoricalMintercept",
    "peer rating" = "b_all_rating_s",
    "years after Phd" = "b_years_from_phd_s",
    "prior belief" = "b_prior_belief_s"
    )
  ) 

post_pred_agg <-  post_pred %>%
  group_by(predictor) %>%
  dplyr::summarise(post_mean = mean(posterior),
            lower95 = quantile(posterior, probs = .025),
            lower50 = quantile(posterior, probs = .25),
            higher50 = quantile(posterior, probs = .75),
            higher95 = quantile(posterior, probs = .975)
            )

# subset for quicker plotting
post_pred_outcome <- post_pred %>% 
  filter(predictor %in% c("duration", "f0", "intensity", "formants"))
post_pred_window <- post_pred %>% 
  filter(predictor %in% c("segment", "word", "phrase", "sentence"))
post_pred_outcome_agg <- post_pred_agg %>% 
  filter(predictor %in% c("duration", "f0", "intensity", "formants"))
post_pred_window_agg <- post_pred_agg %>% 
  filter(predictor %in% c("segment", "word", "phrase", "sentence"))
```

```{r pred-plot}
outcome <- post_pred_outcome %>%
  ggplot(aes(x = reorder(predictor, posterior), y = posterior)) +
    geom_hline(yintercept = 0, lty = "dotted") +
    stat_slab(aes(y = posterior,
                  fill = predictor,
                  fill_ramp = stat(cut_cdf_qi(cdf, 
                                              .width = c(.5, .8, .95),
                                              labels = scales::percent_format()))), 
              color = NA, 
              scale = 0.5, 
              side = "both") +
    scale_fill_ramp_discrete(from = "white", range = c(0.8,0.3)) +
    geom_point(data = post_pred_outcome_agg,
               aes(x = predictor, y = post_mean)) +
    scale_fill_viridis_d(begin = 0, end = 0.8) +
    # annotate("text", x = 1.6, y = -0.02,
    #          hjust= 0, 
    #          size = 2.5,
    #          label = "e.g. analyzing f0 tends to provide\nmore negative effect sizes") +
    # annotate("curve",
    #          x = 1.5, y = -0.02,
    #          xend = 1, yend = -0.045, 
    #          arrow = arrow(angle = 45, length = unit(.2, "cm"))) +
    labs(title = "A: Measurement choice matters.",
         subtitle = "Predictions for different outcomes",
         y = "Effect size difference\n to the overall mean\n") +
    scale_y_continuous(limits = c(-0.08, 0.06),
                       breaks = c(-0.05, 0, 0.05)) +
    theme_classic() +
    theme(legend.position = "none", 
          axis.title.x = element_blank(),
          axis.line = element_blank())

window <- post_pred_window %>%
  ggplot(aes(x = reorder(predictor, posterior), y = posterior)) +
  geom_hline(yintercept = 0,
             lty = "dotted") +
  stat_slab(aes(y = posterior,
                fill = predictor,
                fill_ramp = stat(cut_cdf_qi(cdf, 
                                            .width = c(.5, .8, .95),
                                            labels = scales::percent_format()))), 
            color = NA, 
            scale = 0.5, 
            side = "both") +
  scale_fill_ramp_discrete(from = "white", 
                           range = c(0.8,0.3)) +
  geom_point(data = post_pred_window_agg,
             aes(x = predictor,
                 y = post_mean)) +
  scale_fill_viridis_d(begin = 0,
                       end = 0.8) +
  # annotate("text",
  #          x = 1.6,
  #          y = 0.12,
  #          hjust= 0, 
  #          size = 2.5,
  #          label = "e.g. analyzing sentence patterns tends\nto provide more negative effect sizes") +
  # annotate("curve",
  #          x = 1.5, y = 0.12,
  #          xend = 1, yend = 0.01, 
  #          curvature = 0.3,
  #          arrow = arrow(angle = 45, 
  #                        length = unit(.2, "cm"))) +
  scale_y_continuous(limits = c(-0.2, 0.2),
                       breaks = c(-0.2, -0.1, 0, 0.1, 0.2)) +
  labs(title = "B: Measurement window matters.",
       subtitle = "Predictions for different time windows",
         y = "Effect size difference\n to the overall mean\n") +
  theme_classic() +
  theme(legend.position = "none",
        axis.title.x = element_blank(),
        axis.line = element_blank())

# Combine the plots
predictor_plot <- outcome + window

ggsave(filename = "figs/predictor_plot.png",
       plot = predictor_plot,
       device = "png",
       width = 240, 
       height = 100,
       units = "mm", 
       dpi = 500)
```

```{r pred-plot-all}
post_pred_forest <- predictors_bm_rintercepts %>%
  spread_draws(b_Intercept, 
               b_outcome.durationMintercept,
               b_outcome.f0Mintercept,
               b_outcome.formantsMintercept,
               b_outcome.intensityMintercept,
               b_temporal_window.segmentMintercept,
               b_temporal_window.wordMintercept,
               b_temporal_window.phraseMintercept,
               b_temporal_window.sentenceMintercept,
               b_typicality.categoricalMintercept,
               b_pop_sdi_s,
               b_n_models_s,
               b_all_rating_s,
               b_years_from_phd_s,
               b_prior_belief_s
               ) %>%
  select(-.chain, -.iteration) %>% 
  pivot_longer(-.draw,
               names_to = "predictor", 
               values_to = "posterior") %>% 
 mutate(predictor = fct_recode(
  predictor, 
  "Intercept" = "b_Intercept",
  "duration" = "b_outcome.durationMintercept", 
  "f0" = "b_outcome.f0Mintercept", 
  "intensity" = "b_outcome.intensityMintercept",
  "formants" = "b_outcome.formantsMintercept",
  "segment" = "b_temporal_window.segmentMintercept",
  "word" = "b_temporal_window.wordMintercept",
  "phrase" = "b_temporal_window.phraseMintercept",
  "sentence" = "b_temporal_window.sentenceMintercept",
  "model uniqueness" = "b_pop_sdi_s",
  "team's number of models"  = "b_n_models_s",
  "typicality operationalization" = "b_typicality.categoricalMintercept",
  "peer rating" = "b_all_rating_s",
  "years after Phd" = "b_years_from_phd_s",
  "prior belief" = "b_prior_belief_s"
  )) %>% 
  group_by(predictor) %>%
  dplyr::summarise(post_mean = mean(posterior),
            lower95 = quantile(posterior, probs = .025),
            lower80 = quantile(posterior, probs = .10),
            higher80 = quantile(posterior, probs = .90),
            higher95 = quantile(posterior, probs = .975)
            )


forest <- post_pred_forest %>%
  filter(predictor != "Intercept") %>%
  ggplot(aes(x = post_mean, y = reorder(predictor, post_mean))) +
    geom_vline(xintercept = 0, lty = "dotted") +
    geom_segment(aes(x = lower95, xend = higher95, yend = reorder(predictor, post_mean)),
                 size = 1) +
    geom_segment(aes(x = lower80, xend = higher80, yend = reorder(predictor, post_mean)),
                 size = 2) +
    geom_point(pch = 21, fill = "white", color = "black", size = 4) +
    labs(title = "C: Forest plot",
         subtitle = "Model coefficients for all predictors",
         y = "", x = "\nEffect size difference to the overall mean") +
    theme_classic() +
    theme(legend.position = "none", axis.line = element_blank())


alltogether <- ( outcome / window ) | forest

ggsave(filename = "figs/alltogether.png",
       plot = alltogether,
       device = "png",
       width = 210, 
       height = 145,
       units = "mm", 
       dpi = 500)

```

## Check correlation between predictors

```{r corr}
# check covariance structure:

# select variables
msa_models_corr <- msa_models %>% 
  dplyr::select(
         years_from_phd_s,
         pop_sdi_s,
         n_models_s,
         all_rating_s,
         prior_belief_s) %>% 
  drop_na()

# plot correlations between cont variables
ggcorrplot(cor(msa_models_corr), 
           method = "circle",
           hc.order = TRUE,
           lab = TRUE,
           type = "lower",
           outline.color = "black",
           lab_size = 6)

# higher ratings for more models somehow
ggplot(msa_models_corr,
       aes(x = n_models_s,
                 y = all_rating_s)) +
  geom_point() + 
  geom_smooth(method = "lm")

# run lm equivalent in order to extract vif
predictors_lm <- lm(
  estimate ~
    pop_sdi_s +
    n_models_s +
    outcome +                  # major dimension
    temporal_window +          # temporal window
    typicality +
    all_rating_s +
    years_from_phd_s +
    prior_belief_s,
  data = msa_models
)

#calculate vif
car::vif(predictors_lm)

# looks like predictors do not have concering VIFs
```


