---
title: "Prospective simulation"
date: "`r Sys.Date()`"
output:
  rmdformats::downcute:
    toc_depth: 3
    number_sections: yes
    use_bookdown: yes
bibliography: "`r here::here('./RR_manuscript/other_refs.bib')`"
cls: unified-style-sheet-for-linguistics.csl
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
library(rmdformats)
library(tidyverse)
theme_set(theme_light())
library(patchwork)
library(brms)
library(extraDistr)
library(HDInterval)
library(betapart)
# library(summarytools)
my_seed <- 115116106
```

# Simulate data

We first simulate a dataset (`eta_tbl`) of standardised effect sizes.
Each team ($n = 12$) contributes one standardized effect size $\eta_i$, with respective standard error $\text{se}_i$.

## Helper functions

Let's create helper functions:

* `at_least()` ensures that there is at least a `1` when sampling for predictors (= there must be at least one predictor in the model).

* `sdi_mean()` calculates the mean SDI for the pop-level and group-level predictions.

```{r helpers}
at_least <- function(x) {
  if (1 %in% x) {x} else {sample(c(1, 0, 0, 0, 0))}
}

sdi_mean <- function(preds) {
  bpair <- tibble::tibble(preds) %>% tidyr::unnest_wider(preds, names_sep = ".") %>%
    as.matrix() %>%
    betapart::beta.pair(.)
  sdim <- as.matrix(bpair$beta.sor)
  diag(sdim) <- NA
  rowSums(sdim, na.rm = T) / length(preds)
}
```


## Tibble

The $\eta_i$ is randomly sampled from a $Normal(1, 0.5)$ distribution, while $\text{se}_i$ from a $HalfCauchy(0, 0.15)$.
See comments in code for the other variables.

```{r sim-data}
set.seed(my_seed)

# Number of teams, each team contributes one effect size
n <- 12
# standardized effect size
eta <- rnorm(n, 1, 0.5)
# standard error of the standardised effect size
se <- rhcauchy(n, 0.15)
# label each team
team <- letters[1:n]

# pop-level predictors
pop_pred <- lapply(replicate(n, list(rbinom(5, 1, 0.5))), at_least)
# group-level predictors
group_pred <- lapply(replicate(n, list(rbinom(5, 1, 0.5))), at_least)
# number of post-hoc changes to the measures
phoc_n <- rpois(n, 1)
# number of models run
mod_n <- sample(1:5, n, replace = T)
# major dimension
mdim <- sample(c("duration", "amplitude", "f0", "spectral", "other"), n, TRUE)
# temporal window
twin <- sample(c("segment", "syllable", "word", "phrase"), n, T)
# was data excluded?
excl <- rbinom(n, 1, 0.5)
# reviewers' ratings
rating <- replicate(n, sample(0:100, sample(3:4, 1), replace = T))

# research experience as years from PhD
exp <- replicate(n, sample(-3:20, sample(1:10, 1), replace = T))
# prior belief in the research hypothesis
belf <- lapply(lengths(exp), function(.x) rbinom(.x, 1, 0.5))
```

We can now put the tibble together.

```{r eta-tbl}
# put together in a tibble
eta_tbl <- tibble(
  eta,
  se,
  team,
  pop_pred,
  pop_n = map(pop_pred, sum),
  group_pred,
  group_n = map(group_pred, sum),
  pop_sdi = sdi_mean(pop_pred),
  group_sdi = sdi_mean(group_pred),
  phoc_n,
  mod_n,
  mdim,
  twin,
  excl,
  rating,
  exp,
  belf,
  rating_mean = unlist(map(rating, mean)),
  rating_sd = unlist(map(rating, sd)),
  exp_mean = unlist(map(exp, mean)),
  exp_sd = unlist(map(exp, sd)),
  belf_mean = unlist(map(belf, mean)),
  belf_sd = unlist(map(belf, sd))
) %>%
  mutate(
    # need the following in cases where score = 0
    rating_mean = ifelse(rating_mean == 0, 0.01, rating_mean),
    exp_mean = ifelse(exp_mean == 0, 0.01, exp_mean),
    belf_mean = ifelse(belf_mean == 0, 0.01, belf_mean),
    # need the following in cases where there is only one person in the team
    rating_sd = ifelse(is.na(rating_sd) | rating_sd == 0, 0.01, rating_sd),
    exp_sd = ifelse(is.na(exp_sd) | exp_sd == 0, 0.01, exp_sd),
    belf_sd = ifelse(is.na(belf_sd) | belf_sd == 0, 0.01, belf_sd)
  )
```

# Meta-analytical model

**See paper for more details.**

To summarize the variability in reported effect sized, we will follow Bayesian random-effects meta-analytical techniques.
Since the variables used by the analysis teams might substantially differ in their measurement scales (e.g, Hz for frequency vs ms for duration), we will standardize all reported effects by refitting each reported model with centered and scaled continuous variables (*z*-scores, i.e. the observed values subtracted from the mean divided by the standard deviation) and sum-coded factor variables.

## Model formula

The estimated coefficients of the critical predictors (i.e. critical according to the analysis teams' self-reported inferential criteria), as obtained from the standardized models, will be used as the standardized effect size ($\eta_i$) of each reported model.
If multiple predictors within a single analysis have been reported as critical, each will be included in the meta-analytical model (described in details in the next paragraph).
Moreover, to account for the differing degree of uncertainty around each standardized effect size, we will use the standard deviation of each effect size returned by the standardized models as the standard error ($\text{se}_i$) of the effect size.

After having obtained the standardized effect sizes $\eta_i$ with related standard errors $\text{se}_i$, for each critical predictor of the individual reported analyses, the initiating authors will fit a Bayesian random-effects meta-analysis using a multilevel (intercept-only) regression model, as described in the following.
The outcome variable will be the set of standardized effect sizes $\eta_i$.
The likelihood of $\eta_i$ is assumed to correspond to a normal distribution [@knight2000].
The analysis teams will be entered as a group-level effect (i.e., random effect, `(1 | team)`).
The standard errors $\text{se}_i$ will be included as the standard deviation $\sigma_i$ of $\eta_i$ to fit a measurement-error model, as discussed above.
We will use regularizing weakly-informative priors for the intercept $\alpha$ ($Normal(0, 1)$) and for the group-level standard deviation $\alpha_{\text{t}[i]}$ ($HalfCauchy(0, 1)$).

$$
\begin{aligned}
\eta_i      & \sim \text{Normal}(\mu_i, \sigma_i) \\
\mu_i       & = \alpha + \alpha_{\text{t}[i]} \\
\alpha      & \sim \text{Normal}(0, 1) \\
\sigma_{\alpha_{\text{t}}} & \sim \text{HalfCauchy}(0, 1) \\
\sigma_i    & = \text{se}_i
\end{aligned}
$$

## Model priors

For the meta-analytical model, we will use the following priors:

- A $Normal(0, 1)$ distribution for the prior of the intercept.
- A $HalfCauchy(0, 1)$ distribution for the prior of the teams' intercept standard deviation.

```{r sd-prior}
tibble(
  x = seq(0, 10, by = 0.05),
  density = dhcauchy(x, 1)
) %>%
  ggplot(aes(x, density)) +
  geom_area(fill = "#325756", alpha = 0.9) +
  labs(
    title = "HalfCauchy(0, 1)",
    x = "teams' intercept standard deviation"
  )
```


```{r meta-priors}
priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(cauchy(0, 1), class = sd)
)
```

### Prior predictive checks

```{r prior-predictive}
meta_bm_ppred <- brm(
  eta | se(se) ~
    (1 | team),
  data = eta_tbl,
  prior = priors,
  sample_prior = "only",
  chain = 4,
  seed = my_seed,
  file = "./models/sim/meta_bm_ppred"
)

ppred_samples <- posterior_samples(meta_bm_ppred) %>%
  rename(intercept = b_Intercept, `group-level SD` = sd_team__Intercept)
```

```{r ppred-posts}
ppred_samples %>%
  pivot_longer(intercept:`group-level SD`, names_to = "term") %>%
  mutate(term = factor(term, levels = c("intercept", "group-level SD"))) %>%
  ggplot(aes(value)) +
  geom_density(colour = NA, fill = "#325756", alpha = 0.9, bw = 0.4) +
  facet_wrap(~ term, scales = "free")
```

```{r ppred-joint-post, message=FALSE, warning=FALSE}
ppred_samples %>%
  select(intercept, `r_team[a,Intercept]`:`r_team[l,Intercept]`) %>%
  pivot_longer(-intercept, names_to = "team") %>%
  mutate(eta = intercept + value) %>%
  ggplot(aes(eta)) +
  geom_density(colour = NA, fill = "#325756", alpha = 0.9, bw = 0.4) +
  xlim(-7, 7)
```

## Run

```{r meta-bm}
meta_bm <- brm(
  eta | se(se) ~
    (1 | team),
  data = eta_tbl,
  prior = priors,
  chain = 4,
  seed = my_seed,
  cores = 4,
  file = "./models/sim/meta_bm"
)
```

```{r meta-bm-summary}
meta_bm
```

```{r plot-meta-bm}
plot(meta_bm)
```

# Factors analysis model

## Model formula

$$
\begin{aligned}
\alpha_{\text{t}[i]}      & \sim \text{Normal}(\mu_{\alpha_{t[i]}}, \sigma_i) \\
\mu_{\alpha_{t[i]}}       & = \beta + \upsilon_u\cdot uniq_i + \upsilon_c\cdot cons_i + \upsilon_p\cdot phoc_i + \upsilon_m\cdot modn_i \\
 & \qquad + \upsilon_d\cdot mdim_i + \upsilon_w\cdot twin_i + \upsilon_e\cdot excl_i \\
 & \qquad + \upsilon_r\cdot rat_i + \\
 & \qquad + \upsilon_{xp}\cdot rexp_i + \upsilon_{be}\cdot belf_i  \\
\iota      & \sim \text{Normal}(0, 1) \\
\upsilon_{[\ldots]} & \sim \text{Normal}(0,1) \\
rat_i & \sim \text{Normal}(\mu_{rat_i}, \sigma_{rat_i}) \\
resp_i & \sim \text{Normal}(\mu_{resp_i}, \sigma_{resp_i}) \\
belf_i & \sim \text{Normal}(\mu_{belf_i}, \sigma_{belf_i}) \\
\sigma_i    & = \sigma_{\alpha_{t[i]}}
\end{aligned}
$$

## Model priors

```{r factors-priors}
factors_priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 1), class = b),
  prior(normal(0, 1), class = meanme),
  prior(cauchy(0, 1), class = sdme),
  prior(lkj(2), class = corme)
)
```


## Run

```{r factors-bm}
factors_bm <- brm(
  eta | se(se) ~
    pop_sdi +
    phoc_n +
    mod_n +
    mdim +
    twin +
    excl +
    me(rating_mean, rating_sd) +
    me(exp_mean, exp_sd) +
    me(belf_mean, belf_sd),
  data = eta_tbl,
  prior = factors_priors,
  chain = 4,
  iter = 4000,
  control = list(max_treedepth = 15),
  seed = my_seed,
  cores = 4,
  file = "./models/sim/factors_bm"
)
```

# References